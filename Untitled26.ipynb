{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gowtham6699/TextProphet-Multilabel-Text-Classification-with-Ensemble-Techniques/blob/main/Untitled26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the datasets\n",
        "train_features = pd.read_csv('/content/train.csv')\n",
        "train_labels = pd.read_csv('/content/trainLabels.csv')\n",
        "test_features = pd.read_csv('/content/test.csv', header = None)\n",
        "test_features.columns = train_features.columns\n",
        "\n",
        "common_columns = train_features.columns.intersection(test_features.columns)\n",
        "train_features = train_features[common_columns]\n",
        "test_features = test_features[common_columns]\n",
        "\n",
        "# Debug: Check if DataFrames are empty\n",
        "print(\"Train features shape:\", train_features.shape)\n",
        "print(\"Test features shape:\", test_features.shape)\n",
        "\n",
        "# Debug: Check data types\n",
        "print(\"Train features data types:\\n\", train_features.dtypes)\n",
        "print(\"Test features data types:\\n\", test_features.dtypes)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "train_features_imputed = pd.DataFrame(imputer.fit_transform(train_features), columns=train_features.columns)\n",
        "test_features_imputed = pd.DataFrame(imputer.transform(test_features), columns=test_features.columns)\n",
        "\n",
        "# Convert boolean values to numerical\n",
        "train_features_imputed = train_features_imputed.replace({'YES': 1, 'NO': 0})\n",
        "test_features_imputed = test_features_imputed.replace({'YES': 1, 'NO': 0})\n",
        "\n",
        "# Encode categorical features\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for column in train_features_imputed.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    train_features_imputed[column] = le.fit_transform(train_features_imputed[column])\n",
        "\n",
        "    # Transform test data, handling unseen labels\n",
        "    test_values = test_features_imputed[column].astype(str).tolist()\n",
        "    known_labels = set(le.classes_)\n",
        "    transformed_values = [le.transform([x])[0] if x in known_labels else -1 for x in test_values]  # -1 for unseen labels\n",
        "    test_features_imputed[column] = transformed_values\n",
        "\n",
        "# Further steps for feature engineering and model training..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ytJXBBdiFOn",
        "outputId": "9aa3f8f6-4b7d-42e8-d478-d7f053df96ab"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features shape: (9999, 146)\n",
            "Test features shape: (2000, 146)\n",
            "Train features data types:\n",
            " id        int64\n",
            "x1       object\n",
            "x2       object\n",
            "x3       object\n",
            "x4       object\n",
            "         ...   \n",
            "x141     object\n",
            "x142     object\n",
            "x143      int64\n",
            "x144    float64\n",
            "x145    float64\n",
            "Length: 146, dtype: object\n",
            "Test features data types:\n",
            " id        int64\n",
            "x1       object\n",
            "x2       object\n",
            "x3       object\n",
            "x4       object\n",
            "         ...   \n",
            "x141     object\n",
            "x142     object\n",
            "x143      int64\n",
            "x144    float64\n",
            "x145    float64\n",
            "Length: 146, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform feature engineering using existing column names\n",
        "if 'x1' in train_features_imputed.columns and 'x2' in train_features_imputed.columns:\n",
        "    # Example 1: Interaction Terms\n",
        "    train_features_imputed['interaction_feature'] = train_features_imputed['x1'] * train_features_imputed['x2']\n",
        "    test_features_imputed['interaction_feature'] = test_features_imputed['x1'] * test_features_imputed['x2']\n",
        "\n",
        "    # Example 2: Polynomial Features\n",
        "    from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "    train_features_poly = poly.fit_transform(train_features_imputed)\n",
        "    test_features_poly = poly.transform(test_features_imputed)\n",
        "\n",
        "    # Example 3: Dimensionality Reduction (PCA)\n",
        "    from sklearn.decomposition import PCA\n",
        "\n",
        "    pca = PCA(n_components=10)\n",
        "    train_features_pca = pca.fit_transform(train_features_imputed)\n",
        "    test_features_pca = pca.transform(test_features_imputed)\n",
        "else:\n",
        "    print(\"One or more specified columns do not exist in the DataFrame.\")\n"
      ],
      "metadata": {
        "id": "EzpF0l7Ai775"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of samples in train_features_imputed:\", train_features_imputed.shape[0])\n",
        "print(\"Number of samples in train_labels:\", train_labels.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzU2_eE7xFMf",
        "outputId": "4123b373-753e-462f-86a4-f114d53dc6b1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in train_features_imputed: 9999\n",
            "Number of samples in train_labels: 49999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the number of samples in train_labels to match train_features_imputed\n",
        "train_labels_matched = train_labels[:train_features_imputed.shape[0]]\n",
        "\n",
        "# Now train_labels_matched and train_features_imputed should have the same number of samples\n",
        "print(\"Number of samples in train_features_imputed:\", train_features_imputed.shape[0])\n",
        "print(\"Number of samples in train_labels_matched:\", train_labels_matched.shape[0])\n",
        "\n",
        "# Proceed with data splitting and model training using train_features_imputed and train_labels_matched\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upiEX9ezxF66",
        "outputId": "80fdf808-da68-4063-a60a-08bab22d6592"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in train_features_imputed: 9999\n",
            "Number of samples in train_labels_matched: 9999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels_matched[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUiM-mWW1nJC",
        "outputId": "f95f0301-20ce-43ad-dbbf-7ef12f29448a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  y1  y2  y3  y4  y5  y6  y7  y8  y9  ...  y24  y25  y26  y27  y28  y29  \\\n",
            "0   1   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
            "1   2   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
            "2   3   0   0   1   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
            "3   4   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
            "4   5   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0   \n",
            "\n",
            "   y30  y31  y32  y33  \n",
            "0    0    0    0    1  \n",
            "1    0    0    1    0  \n",
            "2    0    0    0    0  \n",
            "3    0    0    0    1  \n",
            "4    0    0    0    1  \n",
            "\n",
            "[5 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Assuming train_labels_matched is a list of lists or a similar format\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_train_binary = mlb.fit_transform(train_labels_matched)\n",
        "\n",
        "# Verify the shape\n",
        "print(f\"Shape of y_train_binary: {y_train_binary.shape}\")  # Should be (9999, number_of_unique_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0R5kwtu5Xm7",
        "outputId": "0432376a-89fe-4b8d-c718-37c7aec46b34"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train_binary: (34, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_matched = train_labels[:train_features_imputed.shape[0]]\n",
        "y_train_binary = mlb.fit_transform(train_labels_matched)"
      ],
      "metadata": {
        "id": "P0jFO4S651QD"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_imputed = train_features_imputed[:y_train_binary.shape[0]]"
      ],
      "metadata": {
        "id": "0Q8ITY5O529f"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_features_imputed, y_train_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the shapes of the split datasets\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of X_val: {X_val.shape}\")\n",
        "print(f\"Shape of y_val: {y_val.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaBimC9z42u_",
        "outputId": "6339255f-9f0f-489f-826b-e3aeedad1e96"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (27, 147)\n",
            "Shape of y_train: (27, 13)\n",
            "Shape of X_val: (7, 147)\n",
            "Shape of y_val: (7, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define the model\n",
        "base_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "multi_target_model = MultiOutputClassifier(base_model, n_jobs=-1)\n",
        "\n",
        "# Train the model\n",
        "multi_target_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "predictions = multi_target_model.predict(X_val).reshape(-1, 13)\n",
        "\n",
        "# Evaluate predictions\n",
        "print(classification_report(y_val, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgViRbFp5LS2",
        "outputId": "8794d410-12b6-4f7b-cf17-8e5b216f6f05"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.33      0.25      0.29         4\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       1.00      1.00      1.00         7\n",
            "\n",
            "   micro avg       0.73      0.40      0.52        20\n",
            "   macro avg       0.10      0.10      0.10        20\n",
            "weighted avg       0.42      0.40      0.41        20\n",
            " samples avg       0.83      0.40      0.51        20\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_val, predictions, zero_division=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB4ZmBLw6BTo",
        "outputId": "823cdbaa-88a3-42e7-ec89-3354c1bbada9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         0\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.33      0.25      0.29         4\n",
            "           3       1.00      1.00      1.00         0\n",
            "           4       1.00      0.00      0.00         1\n",
            "           5       1.00      0.00      0.00         1\n",
            "           6       1.00      0.00      0.00         1\n",
            "           7       1.00      0.00      0.00         1\n",
            "           8       1.00      0.00      0.00         1\n",
            "           9       1.00      0.00      0.00         1\n",
            "          10       1.00      1.00      1.00         0\n",
            "          11       1.00      1.00      1.00         0\n",
            "          12       1.00      1.00      1.00         7\n",
            "\n",
            "   micro avg       0.73      0.40      0.52        20\n",
            "   macro avg       0.87      0.40      0.41        20\n",
            "weighted avg       0.72      0.40      0.41        20\n",
            " samples avg       0.83      0.40      0.51        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sum the occurrences of each label\n",
        "label_counts = np.sum(y_train, axis=0)\n",
        "print(f\"Label counts: {label_counts}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRvxHpnX6r-o",
        "outputId": "66e09e4e-cde3-4bdc-fe0e-249fdc23211a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label counts: [ 3 10  9  7  2  2  2  2  2  2  1  1 26]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "unique, counts = np.unique(y_train_binary, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTqdIVf57jW4",
        "outputId": "5029b3f9-d0a3-47f1-9beb-117c4f7bab5e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 353, 1: 89}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "predictions = multi_target_model.predict(X_val)\n",
        "\n",
        "# Evaluate predictions with zero_division set to handle undefined metrics\n",
        "print(classification_report(y_val, predictions, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-xGZ3gL8NzP",
        "outputId": "8a199838-1963-49b1-d97d-e04d4fb1379e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.33      0.25      0.29         4\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       1.00      1.00      1.00         7\n",
            "\n",
            "   micro avg       0.73      0.40      0.52        20\n",
            "   macro avg       0.10      0.10      0.10        20\n",
            "weighted avg       0.42      0.40      0.41        20\n",
            " samples avg       0.83      0.40      0.51        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = multilabel_confusion_matrix(y_val, predictions)\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmrrvrDq8R1B",
        "outputId": "ec668f30-d050-418e-c4fd-279c28e46b9b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[7 0]\n",
            "  [0 0]]\n",
            "\n",
            " [[3 1]\n",
            "  [3 0]]\n",
            "\n",
            " [[1 2]\n",
            "  [3 1]]\n",
            "\n",
            " [[7 0]\n",
            "  [0 0]]\n",
            "\n",
            " [[6 0]\n",
            "  [1 0]]\n",
            "\n",
            " [[6 0]\n",
            "  [1 0]]\n",
            "\n",
            " [[6 0]\n",
            "  [1 0]]\n",
            "\n",
            " [[6 0]\n",
            "  [1 0]]\n",
            "\n",
            " [[6 0]\n",
            "  [1 0]]\n",
            "\n",
            " [[6 0]\n",
            "  [1 0]]\n",
            "\n",
            " [[7 0]\n",
            "  [0 0]]\n",
            "\n",
            " [[7 0]\n",
            "  [0 0]]\n",
            "\n",
            " [[0 0]\n",
            "  [0 7]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming multi_target_model is your trained model\n",
        "# Assuming X_test_combined is your test feature set after preprocessing\n",
        "\n",
        "# Use the trained model to predict probabilities for the test set\n",
        "predictions = multi_target_model.predict_proba(X_val)\n",
        "\n",
        "# Flatten the predictions for each sample into a single string\n",
        "predictions_str = []\n",
        "for i, prediction in enumerate(predictions):\n",
        "    prediction_str = ','.join(map(str, prediction))\n",
        "    predictions_str.append(prediction_str)\n",
        "\n",
        "# Create a DataFrame with ID and predictions\n",
        "submission_df = pd.DataFrame({'id': range(1, len(predictions_str) + 1),\n",
        "                              'predictions': predictions_str})\n",
        "\n",
        "# Save the predictions into a CSV file\n",
        "submission_df.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "QClLuR0G-aPq"
      },
      "execution_count": 75,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZbO7T8yPRW5sgn8Y1ihOL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}